# LLM Usage Report

All code and documentation were **reviewed and manually edited**

## ðŸ” Tools Used

- **ChatGPT (GPT-4, June 2025 version), model gpt-4o**

## ðŸ“Œ Purposes

- Initial project structure and directory planning
- Drafting documentation (README, LLM_USAGE, ARCHITECTURE)
- Generating code scaffolds (Dockerfile, tests)
- Writing example prompts and logic explanations
- Troubleshooting
- AWS configurations
- Research on AMR and *Klebsiella*

## ðŸ§ª Prompts Used (Examples)

> "Suggest a Git project structure for a Nextflow pipeline with Docker and SLURM"
>  
> "Generate a markdown README for an AMR detection pipeline using Illumina and Nanopore data"
>
> "Write a pytest unit test for a function that parses AMR annotation output"

## ðŸ§¼ Review and Verification

- All code and documentation were **reviewed and manually edited**
- Facts given by the LLM were **manually reviewed**, and occationally challenged or  altered (the models still sometimes produce results which sound plausible, but are inaccurate)
- No confidential or real-world data was pasted into prompts

## ðŸ”’ Data Privacy

- Only mock data or general descriptions were shared with the LLM
- No sequence files, patient identifiable data or private URLs were entered into the model
- The chat history was saved in a project, and will be deleted after the interview



